---
title: "question8"
output: html_document
---

```{r question8, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(class)
library(caret)
library(e1071)
library(pracma)
```

# Question 8
Categorize Ales...
```{r}
# categorize beers as ipa, or other ale (still have orig columns as well as infilled)
beers_categorized <- merged %>%
  mutate(is_ipa = grepl("\\bIPA\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_ale = grepl("\\bale\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_american = grepl("\\bamerican\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_belgian = grepl("\\bbelgian\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_other_ale = (is_ale & !is_ipa)) 

# keep only the ales
only_ales <- beers_categorized %>% filter(is_ipa | is_other_ale)

# and make a factor for the type
# here I replace orig columns with infilled columns.
for_knn <- only_ales %>% 
  filter(is_ipa | is_other_ale) %>%
  mutate(category = as.factor(ifelse(is_ipa,'IPA','Other'))) %>%
  select(-IBU,-ABV) %>%
  rename(IBU=IBUfill,ABV=ABVfill) %>%
  mutate(abv_z = scale(ABV), ibu_z = scale(IBU)) %>%
  select(ABV,IBU,abv_z,ibu_z,category)

# here I leave orig columns alone, but drop observations with missing values.
for_orig_plot <- only_ales %>% 
  filter(is_ipa | is_other_ale) %>%
  mutate(category = as.factor(ifelse(is_ipa,'IPA','Other'))) %>%
  drop_na(ABV,IBU)

# columns to use for predictors
knn_pred_indices = c("abv_z","ibu_z")                                                

# counts
total_count <- nrow(beers_raw)
ipa_count <- only_ales %>% filter(is_ipa) %>% nrow()
other_count <- only_ales %>% filter(is_other_ale) %>% nrow()
ale_count <- ipa_count + other_count

ale_percent   <- round(100 * ale_count / total_count)
ipa_percent   <- round(100 * ipa_count / total_count)
other_percent <- round(100 * other_count / total_count)
ipa_percent_of_ales <- round(100 * ipa_count / ale_count)
other_percent_of_ales <- round(100 * other_count / ale_count)
```

Out of a total of `r total_count` beers, `r ipa_count` are IPA and `r other_count` are other ales.

`r ale_percent` % of beers are ales.

`r ipa_percent` % of beers are IPA.

`r ipa_percent_of_ales` % of ales are IPA.


Make a scatter plot of IBU vs ABV, with only IPA's and other ales
```{r}
for_orig_plot %>% ggplot(aes(x=IBU,y=ABV,color=category)) + 
  geom_point() + ggtitle('ABV vs IBU for IPAs and other ales (missing values dropped)') +
  coord_cartesian(ylim = c(0.02,0.1),xlim=c(0,150)) +
  scale_color_manual(breaks = c("IPA", "Other"),
                        values=c("#C8102E", "#13294b"))
```

```{r}
for_knn %>% ggplot(aes(x=IBU,y=ABV,color=category)) + 
  geom_point() + ggtitle('ABV vs IBU for IPAs and other ales (infilled)') +
  coord_cartesian(ylim = c(0.02,0.1),xlim=c(0,150)) +
  scale_color_manual(breaks = c("IPA", "Other"),
                        values=c("#C8102E", "#13294b"))
```

Do KNN classification

```{r}
# for repeatability
set.seed(42)
splitPerc <- .7
iterations <- 100
numks <- 50
my_stats = matrix(nrow=numks,ncol=4)
for (i in 1:numks)
{
  acc  = matrix(nrow=iterations,ncol=1)
  sens = matrix(nrow=iterations,ncol=1)
  spec = matrix(nrow=iterations,ncol=1)
  for (j in 1:iterations)
  {
    trainIndices = sample(1:dim(for_knn)[1],round(splitPerc * dim(for_knn)[1]))
    train = for_knn[trainIndices,]
    test = for_knn[-trainIndices,]
    classifications = knn(train[,knn_pred_indices],
                              test[,knn_pred_indices],
                              as.factor(train$category), prob = TRUE, k = i)
    CM = confusionMatrix(table(as.factor(test$category),classifications))
    acc[j]  = CM$overall[1]
    sens[j] = CM$byClass[1]
    spec[j] = CM$byClass[2]
  }
  my_stats[i,1] = i
  my_stats[i,2] = colMeans(acc)
  my_stats[i,3] = colMeans(sens)
  my_stats[i,4] = colMeans(spec)
}
stats_frame <- data.frame(my_stats)
colnames(stats_frame) <- c("k","accuracy","sensitivity","specificity")
for_plot <- reshape2::melt(stats_frame,id.var='k')
for_plot %>% ggplot(aes(x=k,y=value,col=variable)) + 
  geom_line() +
  xlab('k') +
  ylab('percent') +
  ggtitle('Performance of Classifier by K')
```

```{r}
combined_stats <- stats_frame %>% 
  mutate(sums = accuracy + sensitivity + specificity) 

best_k_acc  <- which.max(combined_stats$accuracy)
best_k_sens <- which.max(combined_stats$sensitivity)
best_k_spec <- which.max(combined_stats$specificity)
best_k_combined <- which.max(combined_stats$sums)


chosen_k = best_k_combined

best_acc <-  round(100*combined_stats$accuracy[chosen_k])
best_sens <- round(100*combined_stats$sensitivity[chosen_k])
best_spec <- round(100*combined_stats$specificity[chosen_k])
```

k of `r best_k_acc`  is best for accuracy
k of `r best_k_sens` is best for sensitivity
k of `r best_k_spec` is best for specificity

we choose `r chosen_k` as best overall


```{r}
splitPerc <- .7
trainIndices = sample(1:dim(for_knn)[1],round(splitPerc * dim(for_knn)[1]))
train = for_knn[trainIndices,]
test = for_knn[-trainIndices,]
classifications = knn(train[,knn_pred_indices],
                      test[,knn_pred_indices],
                      as.factor(train$category), prob = TRUE, k = chosen_k)
CM = confusionMatrix(table(as.factor(test$category),classifications))
CM
```


```{r}
knn_pred <- knn(for_knn[,knn_pred_indices],
                for_knn[,knn_pred_indices],
                as.factor(for_knn$category),k=chosen_k)
with_pred <- cbind(for_knn,knn_pred)
with_pred %>% ggplot(aes(x=IBU,y=ABV,color=knn_pred)) + geom_point() + ggtitle('Predicted Class') +
  scale_color_manual(breaks = c("IPA", "Other"),
                        values=c("#C8102E", "#13294b"))
```

```{r}
plot_title <- paste('Class map from knn with k of',as.character(chosen_k))
ABV <- linspace(min(for_knn$ABV),max(for_knn$ABV),100)
IBU <- linspace(min(for_knn$IBU),max(for_knn$IBU),100)

dummy <- data.frame(ABV=rep(0,100*100),IBU=rep(0,100*100))
cnt <- 0
for (i in 1:100)
{
  for (j in 1:100)
  {
    cnt <- cnt + 1
    dummy[cnt,] <- c(ABV[i],IBU[j])
  }
}
synth <- dummy %>% mutate(abv_z = scale(ABV), ibu_z = scale(IBU))

synth_pred <- knn(for_knn[,knn_pred_indices],
                  synth[,knn_pred_indices],
                  as.factor(for_knn$category),k=chosen_k)
synthetic <- cbind(synth,synth_pred)
synthetic %>% ggplot(aes(x=IBU,y=ABV,color=synth_pred)) + geom_point() + ggtitle(plot_title)
```

Consider t-tests of ABV and IBU

First check normality

```{r}
for_knn %>% ggplot(aes(x=ABV)) +
  geom_histogram(aes(color=category,fill=category),
                 position="identity",alpha=0.4,
                 show.legend = TRUE,bins=21) +
  ggtitle('histogram of ABV by category (infilled)') +
  scale_color_manual(values=c("#C8102E", "#13294b")) +
  scale_fill_manual(values=c("#C8102E", "#13294b"))
```

```{r}
for_knn %>% ggplot(aes(x=IBU)) +
  geom_histogram(aes(color=category,fill=category),
                 position="identity",alpha=0.4,
                 show.legend = TRUE,bins=21) +
  ggtitle('histogram of IBU by category (infilled)') +
  scale_color_manual(values=c("#C8102E", "#13294b")) +
  scale_fill_manual(values=c("#C8102E", "#13294b"))
```

```{r}
t.test(IBU ~ category,for_knn,var.equal=FALSE)
```

```{r}
t.test(ABV ~ category,for_knn,var.equal=FALSE)
```

We know that `r ipa_percent_of_ales` % of ales are IPA, so a blind guess that any 
given Ale is not IPA will have an accuracy of `r other_percent_of_ales`.  It would 
have a sensitivity of 100 % but specificity of 0 %.

Since we know from our t-tests that there is a statistically significant
difference in ABV and in IBU between IPA's and other ales, we should be able
to use information in those values to help make a better model for determining
whether an ale is an IPA or not.  In fact, using KNN as a classifier based 
on ABV and IBU, we can classify an ale as IPA or not with `r best_acc` %
overall accuracy.  This classifier has a sensitivty of `r best_sens` % 
and specificity of `r best_spec` %.

For comparison, have a look at a NB classifier
```{r}
pred_indices <- c("ABV","IBU")
acc_nb = matrix(nrow=iterations,ncol=3)
set.seed(42)
for (j in 1:iterations)
{
  trainIndices = sample(seq(1:length(for_knn$ABV)),
                        round(.7*length(for_knn$ABV)))
  trainBeer = for_knn[trainIndices,]
  testBeer = for_knn[-trainIndices,]
  model_c <- naiveBayes(trainBeer[,pred_indices],trainBeer$category)
  CM_c <- confusionMatrix(table(predict(model_c,testBeer[,pred_indices]),
                                as.factor(testBeer$category)))
                          
  acc_nb[j,1] <- CM_c$overall[1] # accuracy
  acc_nb[j,2] <- CM_c$byClass[1] # sensitivity
  acc_nb[j,3] <- CM_c$byClass[2] # specificity
}
mean_stats <- colMeans(acc_nb)
mean_accuracy <- mean_stats[1]
mean_sensitivity <- mean_stats[2]
mean_specificity <- mean_stats[3]
```

from Naive Bayes.

accuracy is `r mean_accuracy`

sensitivity is `r mean_sensitivity`

specificity is `r mean_specificity`





