---
title: "question8"
output: html_document
---

```{r question8, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(class)
library(caret)
library(e1071)
library(pracma)
```

# Question 8
Categorize Ales...
```{r}
# categorize beers as ipa, or other ale
beers_categorized <- merged %>%
  mutate(is_ipa = grepl("\\bIPA\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_ale = grepl("\\bale\\b",Style,ignore.case = TRUE)) %>%
  mutate(is_other_ale = (is_ale & !is_ipa)) %>%
  select(-IBU,-ABV) %>%
  rename(IBU=IBUfill,ABV=ABVfill)

# keep only the ales
only_ales <- beers_categorized %>% filter(is_ipa | is_other_ale)

# can only work with beers that have valid values,
# and make a factor for the type
for_knn <- only_ales %>% 
  filter(is_ipa | is_other_ale) %>%
  mutate(category = as.factor(ifelse(is_ipa,'IPA','Other'))) %>%
  mutate(abv_z = scale(ABV), ibu_z = scale(IBU)) %>%
  select(ABV,IBU,abv_z,ibu_z,category)

# columns to use for predictors
knn_pred_indices = c("abv_z","ibu_z")                                                

# counts
total_count <- nrow(beers_raw)
ipa_count <- only_ales %>% filter(is_ipa) %>% nrow()
other_count <- only_ales %>% filter(is_other_ale) %>% nrow()
ale_count <- ipa_count + other_count

ale_percent   <- round(100 * ale_count / total_count)
ipa_percent   <- round(100 * ipa_count / total_count)
other_percent <- round(100 * other_count / total_count)
```

Out of a total of `r total_count` beers, `r ipa_count` are IPA and `r other_count` are other ales.

`r ale_percent` of beers are ales.

`r ipa_percent` of beers are IPA.

Make a scatter plot of IBU vs ABV, with only IPA's and other ales
```{r}
for_knn %>% ggplot(aes(x=IBU,y=ABV,color=category)) + 
  geom_point() + ggtitle('ABV vs IBU for IPAs and other ales') +
  scale_color_manual(breaks = c("IPA", "Other"),
                        values=c("#C8102E", "#13294b"))
```

Do KNN classification
```{r}
# for repeatability
set.seed(42)
splitPerc <- .7
iterations <- 50
numks <- 50
acc <- matrix(nrow=iterations,ncol=numks)
for (j in 1:iterations)
  {
    accs = data.frame(accuracy = numeric(numks), k = numeric(numks))
    trainIndices = sample(1:dim(for_knn)[1],round(splitPerc * dim(for_knn)[1]))
    train = for_knn[trainIndices,]
    test = for_knn[-trainIndices,]
    for(i in 1:numks)
      {
        classifications = knn(train[,knn_pred_indices],
                              test[,knn_pred_indices],
                              as.factor(train$category), prob = TRUE, k = i)
        table(as.factor(test$category),classifications)
        CM = confusionMatrix(table(as.factor(test$category),classifications))
        acc[j,i] = CM$overall[1]
      }
}
mean_acc <- colMeans(acc)
plot(seq(1,numks,1),mean_acc,type="l")
```

```{r}
best_k <- which.max(mean_acc)
max_acc <- max(mean_acc)
best_k
max_acc
```

k of `r best_k` seems to do the best job.

```{r}
splitPerc <- .7
trainIndices = sample(1:dim(for_knn)[1],round(splitPerc * dim(for_knn)[1]))
train = for_knn[trainIndices,]
test = for_knn[-trainIndices,]
classifications = knn(train[,knn_pred_indices],
                      test[,knn_pred_indices],
                      as.factor(train$category), prob = TRUE, k = best_k)
CM = confusionMatrix(table(as.factor(test$category),classifications))
CM
```


```{r}
knn_pred <- knn(for_knn[,knn_pred_indices],
                for_knn[,knn_pred_indices],
                as.factor(for_knn$category),k=best_k)
with_pred <- cbind(for_knn,knn_pred)
with_pred %>% ggplot(aes(x=IBU,y=ABV,color=knn_pred)) + geom_point() + ggtitle('Predicted Class') +
  scale_color_manual(breaks = c("IPA", "Other"),
                        values=c("#C8102E", "#13294b"))
```

```{r}
ABV <- linspace(min(for_knn$ABV),max(for_knn$ABV),100)
IBU <- linspace(min(for_knn$IBU),max(for_knn$IBU),100)

dummy <- data.frame(ABV=rep(0,100*100),IBU=rep(0,100*100))
cnt <- 0
for (i in 1:100)
{
  for (j in 1:100)
  {
    cnt <- cnt + 1
    dummy[cnt,] <- c(ABV[i],IBU[j])
  }
}
synth <- dummy %>% mutate(abv_z = scale(ABV), ibu_z = scale(IBU))

synth_pred <- knn(for_knn[,knn_pred_indices],
                  synth[,knn_pred_indices],
                  as.factor(for_knn$category),k=best_k)
synthetic <- cbind(synth,synth_pred)
synthetic %>% ggplot(aes(x=IBU,y=ABV,color=synth_pred)) + geom_point() + ggtitle('Class Map')
```

Consider t-tests of ABV and IBU

First check normality

```{r}
for_knn %>% ggplot(aes(x=ABV)) +
  geom_histogram(aes(color=category,fill=category),
                 position="identity",alpha=0.4,
                 show.legend = TRUE,bins=21) +
  ggtitle('histogram of ABV by category') +
  scale_color_manual(values=c("#C8102E", "#13294b")) +
  scale_fill_manual(values=c("#C8102E", "#13294b"))
```

```{r}
for_knn %>% ggplot(aes(x=IBU)) +
  geom_histogram(aes(color=category,fill=category),
                 position="identity",alpha=0.4,
                 show.legend = TRUE,bins=21) +
  ggtitle('histogram of IBU by category') +
  scale_color_manual(values=c("#C8102E", "#13294b")) +
  scale_fill_manual(values=c("#C8102E", "#13294b"))
```

```{r}
t.test(IBU ~ category,for_knn,var.equal=FALSE)
```

```{r}
t.test(ABV ~ category,for_knn,var.equal=FALSE)
```

